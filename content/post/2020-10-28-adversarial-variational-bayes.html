---
title: Adversarial Variational Bayes
author: Mauro Camara Escudero
date: '2020-10-28'
slug: adversarial-variational-bayes
categories:
  - vae
  - gans
  - gan
  - variational-inference
  - variational autoencoder
  - variational
  - generative-models
  - generative-adversarial-networks
  - neural-networks
tags:
  - variational auto encoder
  - variational autoencoder
  - vae
  - gan
  - generative-adversarial-networks
  - generative-models
  - deep generative models
---



<p>On Wednesday <span class="math inline">\(28^{\text{th}}\)</span> of October Mauro presented <a href="https://arxiv.org/pdf/1701.04722.pdf">Adversarial Variational Bayes</a> by Mescheder et al.Â You can find the slides for the presentation <a href="https://neuralnetworksbristol.netlify.com/Adversarial_Variational_Bayes_Mauro.pdf">here</a>. The abstract is given below:</p>
<blockquote>
<p>Variational Autoencoders (VAEs) are expressive
latent variable models that can be used to learn
complex probability distributions from training
data. However, the quality of the resulting model
crucially relies on the expressiveness of the inference model. We introduce Adversarial Variational Bayes (AVB), a technique for training
Variational Autoencoders with arbitrarily expressive inference models. We achieve this by introducing an auxiliary discriminative network
that allows to rephrase the maximum-likelihoodproblem as a two-player game, hence establishing a principled connection between VAEs and
Generative Adversarial Networks (GANs). We
show that in the nonparametric limit our method
yields an exact maximum-likelihood assignment
for the parameters of the generative model, as
well as the exact posterior distribution over the
latent variables given an observation. Contrary
to competing approaches which combine VAEs
with GANs, our approach has a clear theoretical
justification, retains most advantages of standard
Variational Autoencoders and is easy to implement.</p>
</blockquote>

<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.58.3" />


<title>Deep Boltzmann Machines - Neural Networks Reading Group UoB</title>
<meta property="og:title" content="Deep Boltzmann Machines - Neural Networks Reading Group UoB">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/room/">Location</a></li>
    
    <li><a href="/members/">Members</a></li>
    
    <li><a href="/papers/">Past Papers</a></li>
    
    <li><a href="/suggestions/">Reading Suggestions</a></li>
    
    <li><a href="https://github.com/MauroCE/NeuralNetworksReadingGroup">Repo</a></li>
    
    <li><a href="/schedule/">Schedule</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">1 min read</span>
    

    <h1 class="article-title">Deep Boltzmann Machines</h1>

    
    <span class="article-date">2019-12-02</span>
    

    <div class="article-content">
      


<p>On Tuesday 3rd of December Pierre presented the <a href="http://proceedings.mlr.press/v5/salakhutdinov09a/salakhutdinov09a.pdf">paper</a> Deep Bolzmann Machines by Ruslan Salakhutdinov and Geoffrey Hinton. The <a href="https://neuralnetworksbristol.netlify.com/NNRG_Pierre_DBM.pdf">slides</a> are available.</p>
<p>The abstract is given below.</p>
<blockquote>
<p>We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are
estimated using a variational approximation that
tends to focus on a single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two
quite different techniques for estimating the two
types of expectation that enter into the gradient
of the log-likelihood makes it practical to learn
Boltzmann machines with multiple hidden layers and millions of parameters. The learning can
be made more efficient by using a layer-by-layer
“pre-training” phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and
NORB datasets showing that deep Boltzmann
machines learn good generative models and perform well on handwritten digit and visual object
recognition tasks.</p>
</blockquote>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    

    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123451981-4', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>


---
title: Partially Exchangeable Networks and Architectures for Learning Summary Statistics
  in Approximate Bayesian Computation
author: Mauro Camara Escudero
date: '2020-04-07'
slug: partially-exchangeable-networks-and-architectures-for-learning-summary-statistics-in-approximate-bayesian-computation
categories:
  - abc
  - approximate-bayesian-computation
  - sufficient-statistics
  - neural-networks
  - deep-learning
tags:
  - deep-learning
  - abc
  - approximate-bayesian-computation
  - sufficient-statistics
---
On Tuesday 7$^{\text{th}}$ of April Mark Beaumont presented [Partially Exchangeable Networks and Architectures for Learning Summary
Statistics in Approximate Bayesian Computation](https://arxiv.org/pdf/1901.10230.pdf). The abstract is given below.

> We present a novel family of deep neural architectures, named partially exchangeable networks
(PENs) that leverage probabilistic symmetries.
By design, PENs are invariant to block-switch
transformations, which characterize the partial exchangeability properties of conditionally Markovian processes. Moreover, we show that any
block-switch invariant function has a PEN-like
representation. The DeepSets architecture is a
special case of PEN and we can therefore also target fully exchangeable data. We employ PENs to
learn summary statistics in approximate Bayesian
computation (ABC). When comparing PENs to
previous deep learning methods for learning summary statistics, our results are highly competitive,
both considering time series and static models. Indeed, PENs provide more reliable posterior samples even when using less training data
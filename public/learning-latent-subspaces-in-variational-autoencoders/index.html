<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.84.1" />


<title>Learning Latent Subspaces in Variational Autoencoders - Neural Networks Reading Group UoB</title>
<meta property="og:title" content="Learning Latent Subspaces in Variational Autoencoders - Neural Networks Reading Group UoB">


  <link href='https://neuralnetworksbristol.netlify.app/favicon.ico' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/room/">Location</a></li>
    
    <li><a href="/members/">Members</a></li>
    
    <li><a href="/papers/">Past Papers</a></li>
    
    <li><a href="/suggestions/">Reading Suggestions</a></li>
    
    <li><a href="/schedule/">Schedule</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">1 min read</span>
    

    <h1 class="article-title">Learning Latent Subspaces in Variational Autoencoders</h1>

    
    <span class="article-date">2020-11-09</span>
    

    <div class="article-content">
      


<p>On Monday <span class="math inline">\(9^{\text{th}}\)</span> of November Pierre presented <a href="https://arxiv.org/pdf/1812.06190.pdf">Learning Latent Subspaces in
Variational Autoencoders</a> by Klys et al.Â The slides are available <a href="https://neuralnetworksbristol.netlify.com/Conditional_VAE_Pierre.pdf">here</a> and the abstract is given below:</p>
<blockquote>
<p>Variational autoencoders (VAEs) [10, 20] are widely used deep generative models
capable of learning unsupervised latent representations of data. Such representations are often difficult to interpret or control. We consider the problem of
unsupervised learning of features correlated to specific labels in a dataset. We
propose a VAE-based generative model which we show is capable of extracting
features correlated to binary labels in the data and structuring it in a latent subspace
which is easy to interpret. Our model, the Conditional Subspace VAE (CSVAE),
uses mutual information minimization to learn a low-dimensional latent subspace
associated with each label that can easily be inspected and independently manipulated. We demonstrate the utility of the learned representations for attribute
manipulation tasks on both the Toronto Face [23] and CelebA [15] datasets.</p>
</blockquote>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123451981-4', 'auto');
	
	ga('send', 'pageview');
}
</script>
  </body>
</html>


<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.58.3" />


<title>Uniform convergence may be unable to explain generalization in deep learning - Neural Networks Reading Group UoB</title>
<meta property="og:title" content="Uniform convergence may be unable to explain generalization in deep learning - Neural Networks Reading Group UoB">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/room/">Location</a></li>
    
    <li><a href="/members/">Members</a></li>
    
    <li><a href="/papers/">Past Papers</a></li>
    
    <li><a href="/suggestions/">Reading Suggestions</a></li>
    
    <li><a href="https://github.com/MauroCE/NeuralNetworksReadingGroup">Repo</a></li>
    
    <li><a href="/schedule/">Schedule</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">2 min read</span>
    

    <h1 class="article-title">Uniform convergence may be unable to explain generalization in deep learning</h1>

    
    <span class="article-date">2020-03-10</span>
    

    <div class="article-content">
      


<p>On Tuesday 10<span class="math inline">\(^{\text{th}}\)</span> of March Patrick Rubin-Delanchy presented the 2019 NeurIPS <a href="https://arxiv.org/pdf/1902.04742.pdf">paper</a> winner of the Outstanding New Directions Paper Award, titled “Uniform convergence may be unable to explain generalization in deep learning” by Vaishnavh Nagarajan and J. Zico Kolter.</p>
<p>The abstract is given below.</p>
<blockquote>
<p>Aimed at explaining the surprisingly good generalization behavior of overparameterized deep networks, recent works have developed a variety of generalization
bounds for deep learning, all based on the fundamental learning-theoretic technique
of uniform convergence. While it is well-known that many of these existing bounds
are numerically large, through numerous experiments, we bring to light a more
concerning aspect of these bounds: in practice, these bounds can increase with
the training dataset size. Guided by our observations, we then present examples
of overparameterized linear classifiers and neural networks trained by gradient
descent (GD) where uniform convergence provably cannot “explain generalization”
– even if we take into account the implicit bias of GD to the fullest extent possible.
More precisely, even if we consider only the set of classifiers output by GD, which
have test errors less than some small <span class="math inline">\(\epsilon\)</span> in our settings, we show that applying
(two-sided) uniform convergence on this set of classifiers will yield only a vacuous
generalization guarantee larger than 1 − <span class="math inline">\(\epsilon\)</span>. Through these findings, we cast doubt
on the power of uniform convergence-based generalization bounds to provide a
complete picture of why overparameterized deep networks generalize well</p>
</blockquote>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123451981-4', 'auto');
	
	ga('send', 'pageview');
}
</script>

  </body>
</html>


<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>optimal transport on Neural Networks Reading Group UoB</title>
    <link>/tags/optimal-transport/</link>
    <description>Recent content in optimal transport on Neural Networks Reading Group UoB</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 08 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/optimal-transport/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Generalized Sliced Wasserstein Distances</title>
      <link>/generalized-sliced-wasserstein-distances/</link>
      <pubDate>Sat, 08 May 2021 00:00:00 +0000</pubDate>
      
      <guid>/generalized-sliced-wasserstein-distances/</guid>
      <description>On Thusrday the \(6^{\text{th}}\) of May Mingxuan presented Generalized Sliced Wasserstein Distances. The abstract is given below:
 The Wasserstein distance and its variations, e.g., the sliced-Wasserstein (SW) distance, have recently drawn attention from the machine learning community. The SW distance, specifically, was shown to have similar properties to the Wasserstein distance, while being much simpler to compute, and is therefore used in various applications including generative modeling and general supervised/unsupervised learning.</description>
    </item>
    
    <item>
      <title>Differentiable Particle Filtering via Entropy-Regularized Optimal Transport</title>
      <link>/differentiable-particle-filtering-via-entropy-regularized-optimal-transport/</link>
      <pubDate>Thu, 29 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/differentiable-particle-filtering-via-entropy-regularized-optimal-transport/</guid>
      <description>On Thursday the \(29^{\text{th}}\) of April, Mauro presented Differentiable Particle Filtering via Entropy-Regularized Optimal Transport by Corenflos et al.Â You can find the abstract below.
 Particle Filtering (PF) methods are an established class of procedures for performing inference in non-linear state-space models. Resampling is a key ingredient of PF, necessary to obtain low variance likelihood and states estimates. However, traditional resampling methods result in PF-based loss functions being non-differentiable with respect to model and PF parameters.</description>
    </item>
    
    <item>
      <title>From optimal transport to generative modeling: the VEGAN cookbook</title>
      <link>/from-optimal-transport-to-generative-modeling-the-vegan-cookbook/</link>
      <pubDate>Tue, 09 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/from-optimal-transport-to-generative-modeling-the-vegan-cookbook/</guid>
      <description>On Tuesday 9th of June Anthony Lee presented From optimal transport to generative modeling: the VEGAN cookbook. The abstract is given below:
 We study unsupervised generative modeling in terms of the optimal transport (OT) problem between true (but unknown) data distribution PX and the latent variable model distribution PG. We show that the OT problem can be equivalently written in terms of probabilistic encoders, which are constrained to match the posterior and prior distributions over the latent space.</description>
    </item>
    
  </channel>
</rss>

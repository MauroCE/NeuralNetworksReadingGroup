<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.84.1" />


<title>Preventing Posterior Collapse with delta-VAEs - Neural Networks Reading Group UoB</title>
<meta property="og:title" content="Preventing Posterior Collapse with delta-VAEs - Neural Networks Reading Group UoB">


  <link href='/favicon.ico' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="/room/">Location</a></li>
    
    <li><a href="/members/">Members</a></li>
    
    <li><a href="/papers/">Past Papers</a></li>
    
    <li><a href="/suggestions/">Reading Suggestions</a></li>
    
    <li><a href="/schedule/">Schedule</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">1 min read</span>
    

    <h1 class="article-title">Preventing Posterior Collapse with delta-VAEs</h1>

    
    <span class="article-date">2020-05-26</span>
    

    <div class="article-content">
      


<p>On Tuesday 26th of May Pierre Aurelien Gilliot presented <a href="https://arxiv.org/abs/1901.03416">Preventing Posterior Collapse with delta-VAEs</a>. The main reference paper was the original <a href="https://arxiv.org/abs/1312.6114">VAE paper</a>. The abstract is given below.</p>
<blockquote>
<p>Due to the phenomenon of “posterior collapse,” current latent variable generative
models pose a challenging design choice that either weakens the capacity of the
decoder or requires augmenting the objective so it does not only maximize the
likelihood of the data. In this paper, we propose an alternative that utilizes the
most powerful generative models as decoders, whilst optimising the variational
lower bound all while ensuring that the latent variables preserve and encode useful information. Our proposed δ-VAEs achieve this by constraining the variational
family for the posterior to have a minimum distance to the prior. For sequential
latent variable models, our approach resembles the classic representation learning
approach of slow feature analysis. We demonstrate the efficacy of our approach at
modeling text on LM1B and modeling images: learning representations, improving sample quality, and achieving state of the art log-likelihood on CIFAR-<span class="math inline">\(10\)</span> and
ImageNet <span class="math inline">\(32 \times 32\)</span>.</p>
</blockquote>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="/js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-123451981-4', 'auto');
	
	ga('send', 'pageview');
}
</script>
  </body>
</html>


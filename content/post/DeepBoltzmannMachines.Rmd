---
title: Deep Boltzmann Machines
author: Mauro Camara Escudero
date: '2019-12-02'
slug: deep-boltzmann-machines
categories: [Meeting]
tags:
  - boltzmann machines
  - markov random field
  - hopfield networks
---

On Tuesday 3rd of December Pierre presented the [paper](http://proceedings.mlr.press/v5/salakhutdinov09a/salakhutdinov09a.pdf) Deep Bolzmann Machines by Ruslan Salakhutdinov and Geoffrey Hinton. The [slides](https://neuralnetworksbristol.netlify.com/NNRG_Pierre_DBM.pdf) are available.

The abstract is given below.

> We present a new learning algorithm for Boltzmann machines that contain many layers of hidden variables. Data-dependent expectations are
estimated using a variational approximation that
tends to focus on a single mode, and dataindependent expectations are approximated using persistent Markov chains. The use of two
quite different techniques for estimating the two
types of expectation that enter into the gradient
of the log-likelihood makes it practical to learn
Boltzmann machines with multiple hidden layers and millions of parameters. The learning can
be made more efficient by using a layer-by-layer
“pre-training” phase that allows variational inference to be initialized with a single bottomup pass. We present results on the MNIST and
NORB datasets showing that deep Boltzmann
machines learn good generative models and perform well on handwritten digit and visual object
recognition tasks.